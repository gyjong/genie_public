{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff39bbfe43b9409494fc9835e2917438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10000 BL samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples:   6%|▌         | 584/10000 [15:36:41<265:35:01, 101.54s/it]"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    print(\"Loading model and tokenizer...\")\n",
    "    model, tokenizer = load(\"mlx-community/gemma-2-27b-it-4bit\")\n",
    "    return model, tokenizer\n",
    "\n",
    "def load_sample_data(directory):\n",
    "    sample_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(directory, filename), 'r') as f:\n",
    "                sample_data.append(json.load(f))\n",
    "    return sample_data\n",
    "\n",
    "def generate_bl_sample(model, tokenizer, sample_data, max_tokens=2048):\n",
    "    instruction = f\"\"\"\n",
    "    Generate a new JSON object for a Bill of Lading (BL) based on the following structure and examples:\n",
    "    {json.dumps(random.choice(sample_data), indent=2)}\n",
    "\n",
    "    Ensure all fields are filled with realistic and varied data. \n",
    "    Modify values, names, and details to create a unique BL while maintaining the overall structure.\n",
    "    The output should be a valid JSON object.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f'<s>[INST] {instruction} [/INST]\\n'\n",
    "    \n",
    "    generated_text = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt=prompt, \n",
    "        max_tokens=max_tokens,\n",
    "        temp=0.7,\n",
    "        top_p=0.95,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    generated_text = generated_text.replace(prompt, \"\").strip()\n",
    "    \n",
    "    # Find the first occurrence of '{' and the last occurrence of '}'\n",
    "    start = generated_text.find('{')\n",
    "    end = generated_text.rfind('}')\n",
    "    \n",
    "    if start != -1 and end != -1 and start < end:\n",
    "        json_str = generated_text[start:end+1]\n",
    "        try:\n",
    "            bl_data = json.loads(json_str)\n",
    "            return bl_data\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to parse JSON. Retrying...\")\n",
    "    else:\n",
    "        print(\"No valid JSON structure found. Retrying...\")\n",
    "    return None\n",
    "\n",
    "def create_bl_samples(model, tokenizer, sample_data_dir, output_dir, num_samples=10000):\n",
    "    sample_data = load_sample_data(sample_data_dir)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Generating {num_samples} BL samples...\")\n",
    "    for i in tqdm(range(num_samples), desc=\"Generating samples\"):\n",
    "        retry_count = 0\n",
    "        while retry_count < 5:  # Limit the number of retries\n",
    "            bl_data = generate_bl_sample(model, tokenizer, sample_data)\n",
    "            if bl_data:\n",
    "                filename = f\"bl_sample_{i+1}.json\"\n",
    "                with open(os.path.join(output_dir, filename), 'w') as f:\n",
    "                    json.dump(bl_data, f, indent=2)\n",
    "                break\n",
    "            retry_count += 1\n",
    "        if retry_count == 5:\n",
    "            print(f\"Failed to generate valid JSON for sample {i+1} after 5 attempts. Skipping...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = load_model_and_tokenizer()\n",
    "    sample_data_dir = \"./si/\"  # Directory containing the sample JSON files\n",
    "    output_dir = \"./bl_sample/\"\n",
    "    create_bl_samples(model, tokenizer, sample_data_dir, output_dir, num_samples=10000)\n",
    "    print(\"Sample generation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "# Constants for the specific conditions\n",
    "WESTBOUND_PORTS = {\n",
    "    \"loading\": [\"NINGBO\", \"SHANGHAI\", \"YANTIAN\", \"SINGAPORE\", \"TANGER\", \"LE HAVRE\"],\n",
    "    \"discharge\": [\"LE HAVRE\", \"HAMBURG\", \"GDANSK\", \"ROTTERDAM\", \"ALGECIRAS\", \"PORT KLANG\", \"NINGBO\"]\n",
    "}\n",
    "\n",
    "EASTBOUND_PORTS = {\n",
    "    \"loading\": [\"LE HAVRE\", \"HAMBURG\", \"GDANSK\", \"ROTTERDAM\", \"ALGECIRAS\", \"PORT KLANG\", \"NINGBO\"],\n",
    "    \"discharge\": [\"NINGBO\", \"SHANGHAI\", \"YANTIAN\", \"SINGAPORE\", \"TANGER\", \"LE HAVRE\"]\n",
    "}\n",
    "\n",
    "VESSELS = [\n",
    "    \"APL CHANGI\", \"APL MERLION\", \"APL RAFFLES\", \"APL SINGAPURA\", \"APL TEMASEK\",\n",
    "    \"APL VANDA\", \"CMA CGM ALEXANDER VON HUMBOLDT\", \"CMA CGM BENJAMIN FRANKLIN\",\n",
    "    \"CMA CGM BOUGAINVILLE\", \"CMA CGM EOURES\", \"CMA CGM GEORG FORSTER\",\n",
    "    \"CMA CGM GRACE BAY\", \"CMA CGM ROQUEVAIRE\", \"CMA CGM VASCO DE GAMA\",\n",
    "    \"CMA CGM ZHENG HE\"\n",
    "]\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    print(\"Loading model and tokenizer...\")\n",
    "    model, tokenizer = load(\"mlx-community/gemma-2-27b-it-4bit\")\n",
    "    return model, tokenizer\n",
    "\n",
    "def load_sample_data(directory):\n",
    "    sample_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(directory, filename), 'r') as f:\n",
    "                sample_data.append(json.load(f))\n",
    "    return sample_data\n",
    "\n",
    "def generate_bl_sample(model, tokenizer, sample_data, max_tokens=2048):\n",
    "    bound = random.choice([\"W\", \"E\"])\n",
    "    ports = WESTBOUND_PORTS if bound == \"W\" else EASTBOUND_PORTS\n",
    "    vessel = random.choice(VESSELS)\n",
    "    port_of_loading = random.choice(ports[\"loading\"])\n",
    "    port_of_discharge = random.choice(ports[\"discharge\"])\n",
    "\n",
    "    instruction = f\"\"\"\n",
    "    Generate a new JSON object for a Bill of Lading (BL) based on the following structure and examples:\n",
    "    {json.dumps(random.choice(sample_data), indent=2)}\n",
    "\n",
    "    Ensure all fields are filled with realistic and varied data. \n",
    "    Modify values, names, and details to create a unique BL while maintaining the overall structure.\n",
    "    The output should be a valid JSON object.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f'<s>[INST] {instruction} [/INST]\\n'\n",
    "    \n",
    "    generated_text = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt=prompt, \n",
    "        max_tokens=max_tokens,\n",
    "        temp=0.7,\n",
    "        top_p=0.95,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    generated_text = generated_text.replace(prompt, \"\").strip()\n",
    "    \n",
    "    # Find the first occurrence of '{' and the last occurrence of '}'\n",
    "    start = generated_text.find('{')\n",
    "    end = generated_text.rfind('}')\n",
    "    \n",
    "    if start != -1 and end != -1 and start < end:\n",
    "        json_str = generated_text[start:end+1]\n",
    "        try:\n",
    "            bl_data = json.loads(json_str)\n",
    "            # Inject the specific conditions\n",
    "            bl_data[\"voyageDetails\"][\"vesselName\"] = vessel\n",
    "            bl_data[\"voyageDetails\"][\"bound\"] = bound\n",
    "            bl_data[\"routeDetails\"][\"portOfLoading\"] = port_of_loading\n",
    "            bl_data[\"routeDetails\"][\"portOfDischarge\"] = port_of_discharge\n",
    "            return bl_data\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to parse JSON. Retrying...\")\n",
    "    else:\n",
    "        print(\"No valid JSON structure found. Retrying...\")\n",
    "    return None\n",
    "\n",
    "def create_bl_samples(model, tokenizer, sample_data_dir, output_dir, num_samples=10000):\n",
    "    sample_data = load_sample_data(sample_data_dir)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Generating {num_samples} BL samples...\")\n",
    "    for i in tqdm(range(num_samples), desc=\"Generating samples\"):\n",
    "        retry_count = 0\n",
    "        while retry_count < 5:  # Limit the number of retries\n",
    "            bl_data = generate_bl_sample(model, tokenizer, sample_data)\n",
    "            if bl_data:\n",
    "                filename = f\"bl_sample_{i+1}.json\"\n",
    "                with open(os.path.join(output_dir, filename), 'w') as f:\n",
    "                    json.dump(bl_data, f, indent=2)\n",
    "                break\n",
    "            retry_count += 1\n",
    "        if retry_count == 5:\n",
    "            print(f\"Failed to generate valid JSON for sample {i+1} after 5 attempts. Skipping...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = load_model_and_tokenizer()\n",
    "    sample_data_dir = \"./si/\"  # Directory containing the sample JSON files\n",
    "    output_dir = \"./bl_sample/\"\n",
    "    create_bl_samples(model, tokenizer, sample_data_dir, output_dir, num_samples=10000)\n",
    "    print(\"Sample generation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb690368a98418e8f2703830596183a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10000 BL samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples:   0%|          | 29/10000 [46:06<265:48:38, 95.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse JSON. Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples:   6%|▌         | 581/10000 [15:35:41<239:12:03, 91.42s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse JSON. Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples:   7%|▋         | 720/10000 [19:25:42<245:49:49, 95.37s/it] "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "# Constants for the specific conditions\n",
    "WESTBOUND_PORTS = {\n",
    "    \"loading\": [\"NINGBO\", \"SHANGHAI\", \"YANTIAN\", \"SINGAPORE\", \"TANGER\", \"LE HAVRE\"],\n",
    "    \"discharge\": [\"LE HAVRE\", \"HAMBURG\", \"GDANSK\", \"ROTTERDAM\", \"ALGECIRAS\", \"PORT KLANG\", \"NINGBO\"]\n",
    "}\n",
    "\n",
    "EASTBOUND_PORTS = {\n",
    "    \"loading\": [\"LE HAVRE\", \"HAMBURG\", \"GDANSK\", \"ROTTERDAM\", \"ALGECIRAS\", \"PORT KLANG\", \"NINGBO\"],\n",
    "    \"discharge\": [\"NINGBO\", \"SHANGHAI\", \"YANTIAN\", \"SINGAPORE\", \"TANGER\", \"LE HAVRE\"]\n",
    "}\n",
    "\n",
    "VESSELS = [\n",
    "    \"APL CHANGI\", \"APL MERLION\", \"APL RAFFLES\", \"APL SINGAPURA\", \"APL TEMASEK\",\n",
    "    \"APL VANDA\", \"CMA CGM ALEXANDER VON HUMBOLDT\", \"CMA CGM BENJAMIN FRANKLIN\",\n",
    "    \"CMA CGM BOUGAINVILLE\", \"CMA CGM EOURES\", \"CMA CGM GEORG FORSTER\",\n",
    "    \"CMA CGM GRACE BAY\", \"CMA CGM ROQUEVAIRE\", \"CMA CGM VASCO DE GAMA\",\n",
    "    \"CMA CGM ZHENG HE\"\n",
    "]\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    print(\"Loading model and tokenizer...\")\n",
    "    model, tokenizer = load(\"mlx-community/gemma-2-27b-it-4bit\")\n",
    "    return model, tokenizer\n",
    "\n",
    "def load_sample_data(directory):\n",
    "    sample_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(directory, filename), 'r') as f:\n",
    "                sample_data.append(json.load(f))\n",
    "    return sample_data\n",
    "\n",
    "def generate_bl_sample(model, tokenizer, sample_data, max_tokens=2048):\n",
    "    bound = random.choice([\"W\", \"E\"])\n",
    "    ports = WESTBOUND_PORTS if bound == \"W\" else EASTBOUND_PORTS\n",
    "    vessel = random.choice(VESSELS)\n",
    "    port_of_loading = random.choice(ports[\"loading\"])\n",
    "    port_of_discharge = random.choice(ports[\"discharge\"])\n",
    "\n",
    "    instruction = f\"\"\"\n",
    "    Generate a new JSON object for a Bill of Lading (BL) based on the following structure and examples:\n",
    "    {json.dumps(random.choice(sample_data), indent=2)}\n",
    "\n",
    "    Ensure all fields are filled with realistic and varied data. \n",
    "    Modify values, names, and details to create a unique BL while maintaining the overall structure.\n",
    "    The output should be a valid JSON object.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f'<s>[INST] {instruction} [/INST]\\n'\n",
    "    \n",
    "    generated_text = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt=prompt, \n",
    "        max_tokens=max_tokens,\n",
    "        temp=0.7,\n",
    "        top_p=0.95,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    generated_text = generated_text.replace(prompt, \"\").strip()\n",
    "    \n",
    "    # Find the first occurrence of '{' and the last occurrence of '}'\n",
    "    start = generated_text.find('{')\n",
    "    end = generated_text.rfind('}')\n",
    "    \n",
    "    if start != -1 and end != -1 and start < end:\n",
    "        json_str = generated_text[start:end+1]\n",
    "        try:\n",
    "            bl_data = json.loads(json_str)\n",
    "            # Inject the specific conditions\n",
    "            bl_data[\"voyageDetails\"][\"vesselName\"] = vessel\n",
    "            bl_data[\"voyageDetails\"][\"bound\"] = bound\n",
    "            bl_data[\"routeDetails\"][\"portOfLoading\"] = port_of_loading\n",
    "            bl_data[\"routeDetails\"][\"portOfDischarge\"] = port_of_discharge\n",
    "            # Set placeOfReceipt and placeOfDelivery to be the same as portOfLoading and portOfDischarge\n",
    "            bl_data[\"routeDetails\"][\"placeOfReceipt\"] = port_of_loading\n",
    "            bl_data[\"routeDetails\"][\"placeOfDelivery\"] = port_of_discharge\n",
    "            return bl_data\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to parse JSON. Retrying...\")\n",
    "    else:\n",
    "        print(\"No valid JSON structure found. Retrying...\")\n",
    "    return None\n",
    "\n",
    "def create_bl_samples(model, tokenizer, sample_data_dir, output_dir, num_samples=10000):\n",
    "    sample_data = load_sample_data(sample_data_dir)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Generating {num_samples} BL samples...\")\n",
    "    for i in tqdm(range(num_samples), desc=\"Generating samples\"):\n",
    "        retry_count = 0\n",
    "        while retry_count < 5:  # Limit the number of retries\n",
    "            bl_data = generate_bl_sample(model, tokenizer, sample_data)\n",
    "            if bl_data:\n",
    "                filename = f\"bl_sample_{i+1}.json\"\n",
    "                with open(os.path.join(output_dir, filename), 'w') as f:\n",
    "                    json.dump(bl_data, f, indent=2)\n",
    "                break\n",
    "            retry_count += 1\n",
    "        if retry_count == 5:\n",
    "            print(f\"Failed to generate valid JSON for sample {i+1} after 5 attempts. Skipping...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = load_model_and_tokenizer()\n",
    "    sample_data_dir = \"./si/\"  # Directory containing the sample JSON files\n",
    "    output_dir = \"./bl_sample/\"\n",
    "    create_bl_samples(model, tokenizer, sample_data_dir, output_dir, num_samples=10000)\n",
    "    print(\"Sample generation completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
