{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff39bbfe43b9409494fc9835e2917438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10000 BL samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples:   6%|▌         | 584/10000 [15:36:41<265:35:01, 101.54s/it]"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    print(\"Loading model and tokenizer...\")\n",
    "    model, tokenizer = load(\"mlx-community/gemma-2-27b-it-4bit\")\n",
    "    return model, tokenizer\n",
    "\n",
    "def load_sample_data(directory):\n",
    "    sample_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(directory, filename), 'r') as f:\n",
    "                sample_data.append(json.load(f))\n",
    "    return sample_data\n",
    "\n",
    "def generate_bl_sample(model, tokenizer, sample_data, max_tokens=2048):\n",
    "    instruction = f\"\"\"\n",
    "    Generate a new JSON object for a Bill of Lading (BL) based on the following structure and examples:\n",
    "    {json.dumps(random.choice(sample_data), indent=2)}\n",
    "\n",
    "    Ensure all fields are filled with realistic and varied data. \n",
    "    Modify values, names, and details to create a unique BL while maintaining the overall structure.\n",
    "    The output should be a valid JSON object.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f'<s>[INST] {instruction} [/INST]\\n'\n",
    "    \n",
    "    generated_text = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt=prompt, \n",
    "        max_tokens=max_tokens,\n",
    "        temp=0.7,\n",
    "        top_p=0.95,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    generated_text = generated_text.replace(prompt, \"\").strip()\n",
    "    \n",
    "    # Find the first occurrence of '{' and the last occurrence of '}'\n",
    "    start = generated_text.find('{')\n",
    "    end = generated_text.rfind('}')\n",
    "    \n",
    "    if start != -1 and end != -1 and start < end:\n",
    "        json_str = generated_text[start:end+1]\n",
    "        try:\n",
    "            bl_data = json.loads(json_str)\n",
    "            return bl_data\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to parse JSON. Retrying...\")\n",
    "    else:\n",
    "        print(\"No valid JSON structure found. Retrying...\")\n",
    "    return None\n",
    "\n",
    "def create_bl_samples(model, tokenizer, sample_data_dir, output_dir, num_samples=10000):\n",
    "    sample_data = load_sample_data(sample_data_dir)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Generating {num_samples} BL samples...\")\n",
    "    for i in tqdm(range(num_samples), desc=\"Generating samples\"):\n",
    "        retry_count = 0\n",
    "        while retry_count < 5:  # Limit the number of retries\n",
    "            bl_data = generate_bl_sample(model, tokenizer, sample_data)\n",
    "            if bl_data:\n",
    "                filename = f\"bl_sample_{i+1}.json\"\n",
    "                with open(os.path.join(output_dir, filename), 'w') as f:\n",
    "                    json.dump(bl_data, f, indent=2)\n",
    "                break\n",
    "            retry_count += 1\n",
    "        if retry_count == 5:\n",
    "            print(f\"Failed to generate valid JSON for sample {i+1} after 5 attempts. Skipping...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = load_model_and_tokenizer()\n",
    "    sample_data_dir = \"./si/\"  # Directory containing the sample JSON files\n",
    "    output_dir = \"./bl_sample/\"\n",
    "    create_bl_samples(model, tokenizer, sample_data_dir, output_dir, num_samples=10000)\n",
    "    print(\"Sample generation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "# Constants for the specific conditions\n",
    "WESTBOUND_PORTS = {\n",
    "    \"loading\": [\"NINGBO\", \"SHANGHAI\", \"YANTIAN\", \"SINGAPORE\", \"TANGER\", \"LE HAVRE\"],\n",
    "    \"discharge\": [\"LE HAVRE\", \"HAMBURG\", \"GDANSK\", \"ROTTERDAM\", \"ALGECIRAS\", \"PORT KLANG\", \"NINGBO\"]\n",
    "}\n",
    "\n",
    "EASTBOUND_PORTS = {\n",
    "    \"loading\": [\"LE HAVRE\", \"HAMBURG\", \"GDANSK\", \"ROTTERDAM\", \"ALGECIRAS\", \"PORT KLANG\", \"NINGBO\"],\n",
    "    \"discharge\": [\"NINGBO\", \"SHANGHAI\", \"YANTIAN\", \"SINGAPORE\", \"TANGER\", \"LE HAVRE\"]\n",
    "}\n",
    "\n",
    "VESSELS = [\n",
    "    \"APL CHANGI\", \"APL MERLION\", \"APL RAFFLES\", \"APL SINGAPURA\", \"APL TEMASEK\",\n",
    "    \"APL VANDA\", \"CMA CGM ALEXANDER VON HUMBOLDT\", \"CMA CGM BENJAMIN FRANKLIN\",\n",
    "    \"CMA CGM BOUGAINVILLE\", \"CMA CGM EOURES\", \"CMA CGM GEORG FORSTER\",\n",
    "    \"CMA CGM GRACE BAY\", \"CMA CGM ROQUEVAIRE\", \"CMA CGM VASCO DE GAMA\",\n",
    "    \"CMA CGM ZHENG HE\"\n",
    "]\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    print(\"Loading model and tokenizer...\")\n",
    "    model, tokenizer = load(\"mlx-community/gemma-2-27b-it-4bit\")\n",
    "    return model, tokenizer\n",
    "\n",
    "def load_sample_data(directory):\n",
    "    sample_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(directory, filename), 'r') as f:\n",
    "                sample_data.append(json.load(f))\n",
    "    return sample_data\n",
    "\n",
    "def generate_bl_sample(model, tokenizer, sample_data, max_tokens=2048):\n",
    "    bound = random.choice([\"W\", \"E\"])\n",
    "    ports = WESTBOUND_PORTS if bound == \"W\" else EASTBOUND_PORTS\n",
    "    vessel = random.choice(VESSELS)\n",
    "    port_of_loading = random.choice(ports[\"loading\"])\n",
    "    port_of_discharge = random.choice(ports[\"discharge\"])\n",
    "\n",
    "    instruction = f\"\"\"\n",
    "    Generate a new JSON object for a Bill of Lading (BL) based on the following structure and examples:\n",
    "    {json.dumps(random.choice(sample_data), indent=2)}\n",
    "\n",
    "    Ensure all fields are filled with realistic and varied data. \n",
    "    Modify values, names, and details to create a unique BL while maintaining the overall structure.\n",
    "    The output should be a valid JSON object.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f'<s>[INST] {instruction} [/INST]\\n'\n",
    "    \n",
    "    generated_text = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt=prompt, \n",
    "        max_tokens=max_tokens,\n",
    "        temp=0.7,\n",
    "        top_p=0.95,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    generated_text = generated_text.replace(prompt, \"\").strip()\n",
    "    \n",
    "    # Find the first occurrence of '{' and the last occurrence of '}'\n",
    "    start = generated_text.find('{')\n",
    "    end = generated_text.rfind('}')\n",
    "    \n",
    "    if start != -1 and end != -1 and start < end:\n",
    "        json_str = generated_text[start:end+1]\n",
    "        try:\n",
    "            bl_data = json.loads(json_str)\n",
    "            # Inject the specific conditions\n",
    "            bl_data[\"voyageDetails\"][\"vesselName\"] = vessel\n",
    "            bl_data[\"voyageDetails\"][\"bound\"] = bound\n",
    "            bl_data[\"routeDetails\"][\"portOfLoading\"] = port_of_loading\n",
    "            bl_data[\"routeDetails\"][\"portOfDischarge\"] = port_of_discharge\n",
    "            return bl_data\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to parse JSON. Retrying...\")\n",
    "    else:\n",
    "        print(\"No valid JSON structure found. Retrying...\")\n",
    "    return None\n",
    "\n",
    "def create_bl_samples(model, tokenizer, sample_data_dir, output_dir, num_samples=10000):\n",
    "    sample_data = load_sample_data(sample_data_dir)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Generating {num_samples} BL samples...\")\n",
    "    for i in tqdm(range(num_samples), desc=\"Generating samples\"):\n",
    "        retry_count = 0\n",
    "        while retry_count < 5:  # Limit the number of retries\n",
    "            bl_data = generate_bl_sample(model, tokenizer, sample_data)\n",
    "            if bl_data:\n",
    "                filename = f\"bl_sample_{i+1}.json\"\n",
    "                with open(os.path.join(output_dir, filename), 'w') as f:\n",
    "                    json.dump(bl_data, f, indent=2)\n",
    "                break\n",
    "            retry_count += 1\n",
    "        if retry_count == 5:\n",
    "            print(f\"Failed to generate valid JSON for sample {i+1} after 5 attempts. Skipping...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = load_model_and_tokenizer()\n",
    "    sample_data_dir = \"./si/\"  # Directory containing the sample JSON files\n",
    "    output_dir = \"./bl_sample/\"\n",
    "    create_bl_samples(model, tokenizer, sample_data_dir, output_dir, num_samples=10000)\n",
    "    print(\"Sample generation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation sample si dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb690368a98418e8f2703830596183a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10000 BL samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples:   0%|          | 29/10000 [46:06<265:48:38, 95.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse JSON. Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples:   6%|▌         | 581/10000 [15:35:41<239:12:03, 91.42s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse JSON. Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples:   7%|▋         | 720/10000 [19:25:42<245:49:49, 95.37s/it] "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "# Constants for the specific conditions\n",
    "WESTBOUND_PORTS = {\n",
    "    \"loading\": [\"NINGBO\", \"SHANGHAI\", \"YANTIAN\", \"SINGAPORE\", \"TANGER\", \"LE HAVRE\"],\n",
    "    \"discharge\": [\"LE HAVRE\", \"HAMBURG\", \"GDANSK\", \"ROTTERDAM\", \"ALGECIRAS\", \"PORT KLANG\", \"NINGBO\"]\n",
    "}\n",
    "\n",
    "EASTBOUND_PORTS = {\n",
    "    \"loading\": [\"LE HAVRE\", \"HAMBURG\", \"GDANSK\", \"ROTTERDAM\", \"ALGECIRAS\", \"PORT KLANG\", \"NINGBO\"],\n",
    "    \"discharge\": [\"NINGBO\", \"SHANGHAI\", \"YANTIAN\", \"SINGAPORE\", \"TANGER\", \"LE HAVRE\"]\n",
    "}\n",
    "\n",
    "VESSELS = [\n",
    "    \"APL CHANGI\", \"APL MERLION\", \"APL RAFFLES\", \"APL SINGAPURA\", \"APL TEMASEK\",\n",
    "    \"APL VANDA\", \"CMA CGM ALEXANDER VON HUMBOLDT\", \"CMA CGM BENJAMIN FRANKLIN\",\n",
    "    \"CMA CGM BOUGAINVILLE\", \"CMA CGM EOURES\", \"CMA CGM GEORG FORSTER\",\n",
    "    \"CMA CGM GRACE BAY\", \"CMA CGM ROQUEVAIRE\", \"CMA CGM VASCO DE GAMA\",\n",
    "    \"CMA CGM ZHENG HE\"\n",
    "]\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    print(\"Loading model and tokenizer...\")\n",
    "    model, tokenizer = load(\"mlx-community/gemma-2-27b-it-4bit\")\n",
    "    return model, tokenizer\n",
    "\n",
    "def load_sample_data(directory):\n",
    "    sample_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(directory, filename), 'r') as f:\n",
    "                sample_data.append(json.load(f))\n",
    "    return sample_data\n",
    "\n",
    "def generate_bl_sample(model, tokenizer, sample_data, max_tokens=2048):\n",
    "    bound = random.choice([\"W\", \"E\"])\n",
    "    ports = WESTBOUND_PORTS if bound == \"W\" else EASTBOUND_PORTS\n",
    "    vessel = random.choice(VESSELS)\n",
    "    port_of_loading = random.choice(ports[\"loading\"])\n",
    "    port_of_discharge = random.choice(ports[\"discharge\"])\n",
    "\n",
    "    instruction = f\"\"\"\n",
    "    Generate a new JSON object for a Bill of Lading (BL) based on the following structure and examples:\n",
    "    {json.dumps(random.choice(sample_data), indent=2)}\n",
    "\n",
    "    Ensure all fields are filled with realistic and varied data. \n",
    "    Modify values, names, and details to create a unique BL while maintaining the overall structure.\n",
    "    The output should be a valid JSON object.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f'<s>[INST] {instruction} [/INST]\\n'\n",
    "    \n",
    "    generated_text = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt=prompt, \n",
    "        max_tokens=max_tokens,\n",
    "        temp=0.7,\n",
    "        top_p=0.95,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    generated_text = generated_text.replace(prompt, \"\").strip()\n",
    "    \n",
    "    # Find the first occurrence of '{' and the last occurrence of '}'\n",
    "    start = generated_text.find('{')\n",
    "    end = generated_text.rfind('}')\n",
    "    \n",
    "    if start != -1 and end != -1 and start < end:\n",
    "        json_str = generated_text[start:end+1]\n",
    "        try:\n",
    "            bl_data = json.loads(json_str)\n",
    "            # Inject the specific conditions\n",
    "            bl_data[\"voyageDetails\"][\"vesselName\"] = vessel\n",
    "            bl_data[\"voyageDetails\"][\"bound\"] = bound\n",
    "            bl_data[\"routeDetails\"][\"portOfLoading\"] = port_of_loading\n",
    "            bl_data[\"routeDetails\"][\"portOfDischarge\"] = port_of_discharge\n",
    "            # Set placeOfReceipt and placeOfDelivery to be the same as portOfLoading and portOfDischarge\n",
    "            bl_data[\"routeDetails\"][\"placeOfReceipt\"] = port_of_loading\n",
    "            bl_data[\"routeDetails\"][\"placeOfDelivery\"] = port_of_discharge\n",
    "            return bl_data\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to parse JSON. Retrying...\")\n",
    "    else:\n",
    "        print(\"No valid JSON structure found. Retrying...\")\n",
    "    return None\n",
    "\n",
    "def create_bl_samples(model, tokenizer, sample_data_dir, output_dir, num_samples=10000):\n",
    "    sample_data = load_sample_data(sample_data_dir)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Generating {num_samples} BL samples...\")\n",
    "    for i in tqdm(range(num_samples), desc=\"Generating samples\"):\n",
    "        retry_count = 0\n",
    "        while retry_count < 5:  # Limit the number of retries\n",
    "            bl_data = generate_bl_sample(model, tokenizer, sample_data)\n",
    "            if bl_data:\n",
    "                filename = f\"bl_sample_{i+1}.json\"\n",
    "                with open(os.path.join(output_dir, filename), 'w') as f:\n",
    "                    json.dump(bl_data, f, indent=2)\n",
    "                break\n",
    "            retry_count += 1\n",
    "        if retry_count == 5:\n",
    "            print(f\"Failed to generate valid JSON for sample {i+1} after 5 attempts. Skipping...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = load_model_and_tokenizer()\n",
    "    sample_data_dir = \"./si/\"  # Directory containing the sample JSON files\n",
    "    output_dir = \"./bl_sample/\"\n",
    "    create_bl_samples(model, tokenizer, sample_data_dir, output_dir, num_samples=10000)\n",
    "    print(\"Sample generation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation sample bkg and si dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "# Constants for the specific conditions\n",
    "WESTBOUND_PORTS = {\n",
    "    \"loading\": [\"NINGBO\", \"SHANGHAI\", \"YANTIAN\", \"SINGAPORE\", \"TANGER\", \"LE HAVRE\"],\n",
    "    \"discharge\": [\"LE HAVRE\", \"HAMBURG\", \"GDANSK\", \"ROTTERDAM\", \"ALGECIRAS\", \"PORT KLANG\", \"NINGBO\"]\n",
    "}\n",
    "\n",
    "EASTBOUND_PORTS = {\n",
    "    \"loading\": [\"LE HAVRE\", \"HAMBURG\", \"GDANSK\", \"ROTTERDAM\", \"ALGECIRAS\", \"PORT KLANG\", \"NINGBO\"],\n",
    "    \"discharge\": [\"NINGBO\", \"SHANGHAI\", \"YANTIAN\", \"SINGAPORE\", \"TANGER\", \"LE HAVRE\"]\n",
    "}\n",
    "\n",
    "VESSELS = [\n",
    "    \"APL CHANGI\", \"APL MERLION\", \"APL RAFFLES\", \"APL SINGAPURA\", \"APL TEMASEK\",\n",
    "    \"APL VANDA\", \"CMA CGM ALEXANDER VON HUMBOLDT\", \"CMA CGM BENJAMIN FRANKLIN\",\n",
    "    \"CMA CGM BOUGAINVILLE\", \"CMA CGM EOURES\", \"CMA CGM GEORG FORSTER\",\n",
    "    \"CMA CGM GRACE BAY\", \"CMA CGM ROQUEVAIRE\", \"CMA CGM VASCO DE GAMA\",\n",
    "    \"CMA CGM ZHENG HE\"\n",
    "]\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    print(\"Loading model and tokenizer...\")\n",
    "    model, tokenizer = load(\"mlx-community/gemma-2-27b-it-4bit\")\n",
    "    return model, tokenizer\n",
    "\n",
    "def load_sample_data(directory):\n",
    "    sample_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(directory, filename), 'r') as f:\n",
    "                sample_data.append(json.load(f))\n",
    "    return sample_data\n",
    "\n",
    "def generate_booking_reference():\n",
    "    today = datetime.now()\n",
    "    return f\"CHERRY{today.strftime('%Y%m%d')}{random.randint(1000, 9999)}\"\n",
    "\n",
    "def generate_bkg_sample(model, tokenizer, sample_data, booking_reference, max_tokens=2048):\n",
    "    bound = random.choice([\"W\", \"E\"])\n",
    "    ports = WESTBOUND_PORTS if bound == \"W\" else EASTBOUND_PORTS\n",
    "    vessel = random.choice(VESSELS)\n",
    "    port_of_loading = random.choice(ports[\"loading\"])\n",
    "    port_of_discharge = random.choice(ports[\"discharge\"])\n",
    "\n",
    "    instruction = f\"\"\"\n",
    "    Generate a new JSON object for a Booking based on the following structure and examples:\n",
    "    {json.dumps(random.choice(sample_data), indent=2)}\n",
    "\n",
    "    Ensure all fields are filled with realistic and varied data. \n",
    "    Modify values, names, and details to create a unique Booking while maintaining the overall structure.\n",
    "    The output should be a valid JSON object.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f'<s>[INST] {instruction} [/INST]\\n'\n",
    "    \n",
    "    generated_text = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt=prompt, \n",
    "        max_tokens=max_tokens,\n",
    "        temp=0.7,\n",
    "        top_p=0.95,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    generated_text = generated_text.replace(prompt, \"\").strip()\n",
    "    \n",
    "    start = generated_text.find('{')\n",
    "    end = generated_text.rfind('}')\n",
    "    \n",
    "    if start != -1 and end != -1 and start < end:\n",
    "        json_str = generated_text[start:end+1]\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "            # Inject the specific conditions\n",
    "            data[\"bookingReference\"] = booking_reference\n",
    "            data[\"voyageDetails\"][\"vesselName\"] = vessel\n",
    "            data[\"voyageDetails\"][\"bound\"] = bound\n",
    "            data[\"routeDetails\"][\"portOfLoading\"] = port_of_loading\n",
    "            data[\"routeDetails\"][\"portOfDischarge\"] = port_of_discharge\n",
    "            data[\"routeDetails\"][\"placeOfReceipt\"] = port_of_loading\n",
    "            data[\"routeDetails\"][\"placeOfDelivery\"] = port_of_discharge\n",
    "            return data\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to parse JSON. Retrying...\")\n",
    "    else:\n",
    "        print(\"No valid JSON structure found. Retrying...\")\n",
    "    return None\n",
    "\n",
    "def generate_si_sample(model, tokenizer, sample_data, bkg_data, max_tokens=2048):\n",
    "    instruction = f\"\"\"\n",
    "    Generate a new JSON object for a Shipping Instruction based on the following structure and examples:\n",
    "    {json.dumps(random.choice(sample_data), indent=2)}\n",
    "\n",
    "    Ensure all fields are filled with realistic and varied data. \n",
    "    Modify values, names, and details to create a unique SI while maintaining the overall structure.\n",
    "    Use the following booking data as reference:\n",
    "    {json.dumps(bkg_data, indent=2)}\n",
    "    The output should be a valid JSON object.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f'<s>[INST] {instruction} [/INST]\\n'\n",
    "    \n",
    "    generated_text = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt=prompt, \n",
    "        max_tokens=max_tokens,\n",
    "        temp=0.7,\n",
    "        top_p=0.95,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    generated_text = generated_text.replace(prompt, \"\").strip()\n",
    "    \n",
    "    start = generated_text.find('{')\n",
    "    end = generated_text.rfind('}')\n",
    "    \n",
    "    if start != -1 and end != -1 and start < end:\n",
    "        json_str = generated_text[start:end+1]\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "            # Ensure SI data uses the same key information as BKG data\n",
    "            data[\"bookingReference\"] = bkg_data[\"bookingReference\"]\n",
    "            data[\"voyageDetails\"] = bkg_data[\"voyageDetails\"]\n",
    "            data[\"routeDetails\"] = bkg_data[\"routeDetails\"]\n",
    "            \n",
    "            # Additional shared information\n",
    "            if \"partyDetails\" in bkg_data and \"shipper\" in bkg_data[\"partyDetails\"]:\n",
    "                if \"partyDetails\" not in data:\n",
    "                    data[\"partyDetails\"] = {}\n",
    "                data[\"partyDetails\"][\"shipper\"] = bkg_data[\"partyDetails\"][\"shipper\"]\n",
    "            \n",
    "            if \"containers\" in bkg_data:\n",
    "                data[\"containers\"] = bkg_data[\"containers\"]\n",
    "            \n",
    "            if \"additionalInformation\" in bkg_data:\n",
    "                if \"additionalInformation\" not in data:\n",
    "                    data[\"additionalInformation\"] = {}\n",
    "                if \"additionalRemarks\" in bkg_data[\"additionalInformation\"]:\n",
    "                    data[\"additionalInformation\"][\"additionalRemarks\"] = bkg_data[\"additionalInformation\"][\"additionalRemarks\"]\n",
    "                if \"onboardDate\" in bkg_data[\"additionalInformation\"]:\n",
    "                    data[\"additionalInformation\"][\"onboardDate\"] = bkg_data[\"additionalInformation\"][\"onboardDate\"]\n",
    "            \n",
    "            if \"totalShipment\" in bkg_data:\n",
    "                data[\"totalShipment\"] = bkg_data[\"totalShipment\"]\n",
    "            \n",
    "            if \"outOfGaugeDimensions\" in bkg_data:\n",
    "                data[\"outOfGaugeDimensions\"] = bkg_data[\"outOfGaugeDimensions\"]\n",
    "            \n",
    "            if \"dangerousGoods\" in bkg_data:\n",
    "                data[\"dangerousGoods\"] = bkg_data[\"dangerousGoods\"]\n",
    "            \n",
    "            if \"reeferSettings\" in bkg_data:\n",
    "                data[\"reeferSettings\"] = bkg_data[\"reeferSettings\"]\n",
    "            \n",
    "            return data\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to parse JSON. Retrying...\")\n",
    "    else:\n",
    "        print(\"No valid JSON structure found. Retrying...\")\n",
    "    return None\n",
    "\n",
    "def create_samples(model, tokenizer, sample_data_bkg, sample_data_si, output_dir_bkg, output_dir_si, num_samples=10000):\n",
    "    sample_data_bkg = load_sample_data(sample_data_bkg)\n",
    "    sample_data_si = load_sample_data(sample_data_si)\n",
    "    \n",
    "    os.makedirs(output_dir_bkg, exist_ok=True)\n",
    "    os.makedirs(output_dir_si, exist_ok=True)\n",
    "    \n",
    "    print(f\"Generating {num_samples} pairs of Booking and SI samples...\")\n",
    "    for i in tqdm(range(num_samples), desc=\"Generating samples\"):\n",
    "        booking_reference = generate_booking_reference()\n",
    "        \n",
    "        retry_count = 0\n",
    "        while retry_count < 5:  # Limit the number of retries\n",
    "            bkg_data = generate_bkg_sample(model, tokenizer, sample_data_bkg, booking_reference)\n",
    "            if bkg_data:\n",
    "                si_data = generate_si_sample(model, tokenizer, sample_data_si, bkg_data)\n",
    "                if si_data:\n",
    "                    bkg_filename = f\"bkg_{booking_reference}.json\"\n",
    "                    si_filename = f\"si_{booking_reference}.json\"\n",
    "                    \n",
    "                    with open(os.path.join(output_dir_bkg, bkg_filename), 'w') as f:\n",
    "                        json.dump(bkg_data, f, indent=2)\n",
    "                    with open(os.path.join(output_dir_si, si_filename), 'w') as f:\n",
    "                        json.dump(si_data, f, indent=2)\n",
    "                    break\n",
    "            retry_count += 1\n",
    "        if retry_count == 5:\n",
    "            print(f\"Failed to generate valid JSON for sample {i+1} after 5 attempts. Skipping...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = load_model_and_tokenizer()\n",
    "    sample_data_bkg = \"./bkg/\"\n",
    "    sample_data_si = \"./si/\"\n",
    "    output_dir_bkg = \"./bkg_data/\"\n",
    "    output_dir_si = \"./si_data/\"\n",
    "    create_samples(model, tokenizer, sample_data_bkg, sample_data_si, output_dir_bkg, output_dir_si, num_samples=10000)\n",
    "    print(\"Sample generation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More aligned data generation for bkg data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "# Constants for the specific conditions\n",
    "WESTBOUND_PORTS = {\n",
    "    \"loading\": [\"NINGBO\", \"SHANGHAI\", \"YANTIAN\", \"SINGAPORE\", \"TANGER\", \"LE HAVRE\"],\n",
    "    \"discharge\": [\"LE HAVRE\", \"HAMBURG\", \"GDANSK\", \"ROTTERDAM\", \"ALGECIRAS\", \"PORT KLANG\", \"NINGBO\"]\n",
    "}\n",
    "\n",
    "EASTBOUND_PORTS = {\n",
    "    \"loading\": [\"LE HAVRE\", \"HAMBURG\", \"GDANSK\", \"ROTTERDAM\", \"ALGECIRAS\", \"PORT KLANG\", \"NINGBO\"],\n",
    "    \"discharge\": [\"NINGBO\", \"SHANGHAI\", \"YANTIAN\", \"SINGAPORE\", \"TANGER\", \"LE HAVRE\"]\n",
    "}\n",
    "\n",
    "VESSELS = [\n",
    "    \"APL CHANGI\", \"APL MERLION\", \"APL RAFFLES\", \"APL SINGAPURA\", \"APL TEMASEK\",\n",
    "    \"APL VANDA\", \"CMA CGM ALEXANDER VON HUMBOLDT\", \"CMA CGM BENJAMIN FRANKLIN\",\n",
    "    \"CMA CGM BOUGAINVILLE\", \"CMA CGM EOURES\", \"CMA CGM GEORG FORSTER\",\n",
    "    \"CMA CGM GRACE BAY\", \"CMA CGM ROQUEVAIRE\", \"CMA CGM VASCO DE GAMA\",\n",
    "    \"CMA CGM ZHENG HE\"\n",
    "]\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    print(\"Loading model and tokenizer...\")\n",
    "    model, tokenizer = load(\"mlx-community/gemma-2-27b-it-4bit\")\n",
    "    return model, tokenizer\n",
    "\n",
    "def load_sample_data(directory):\n",
    "    sample_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(directory, filename), 'r') as f:\n",
    "                sample_data.append(json.load(f))\n",
    "    return sample_data\n",
    "\n",
    "def generate_booking_reference():\n",
    "    today = datetime.now()\n",
    "    random_days = random.randint(0, 60)  # 0에서 60일 사이의 랜덤한 일수\n",
    "    future_date = today + timedelta(days=random_days)\n",
    "    return f\"CHERRY{future_date.strftime('%Y%m%d')}{random.randint(1000, 9999)}\"\n",
    "\n",
    "def generate_bkg_sample(model, tokenizer, sample_data, booking_reference, max_tokens=2048):\n",
    "    bound = random.choice([\"W\", \"E\"])\n",
    "    ports = WESTBOUND_PORTS if bound == \"W\" else EASTBOUND_PORTS\n",
    "    vessel = random.choice(VESSELS)\n",
    "    port_of_loading = random.choice(ports[\"loading\"])\n",
    "    port_of_discharge = random.choice(ports[\"discharge\"])\n",
    "\n",
    "    sample_structure = random.choice(sample_data)\n",
    "\n",
    "    data = {\n",
    "        \"bookingReference\": booking_reference,\n",
    "        \"customerName\": f\"CUSTOMER {random.randint(1000, 9999)}\",\n",
    "        \"shipperName\": f\"SHIPPER {random.randint(1000, 9999)}\",\n",
    "        \"invoiceReceiver\": f\"INVOICE RECEIVER {random.randint(1000, 9999)}\",\n",
    "        \"voyageDetails\": {\n",
    "            \"vesselName\": vessel,\n",
    "            \"voyageNumber\": f\"{datetime.now().year}{random.randint(100, 999)}{bound}\"\n",
    "        },\n",
    "        \"cargoDetails\": {\n",
    "            \"hsCode\": f\"{random.randint(100000, 999999)}\",\n",
    "            \"chapterDescription\": f\"SAMPLE CHAPTER DESCRIPTION {random.randint(1, 100)}\",\n",
    "            \"commodity\": f\"SAMPLE COMMODITY {random.randint(1, 100)}\"\n",
    "        },\n",
    "        \"containerDetails\": {\n",
    "            \"size\": random.choice([\"20 DRY\", \"40 DRY\", \"40 HIGH CUBE\", \"45 HIGH CUBE\"]),\n",
    "            \"type\": random.choice([\"GENERAL PURPOSE\", \"REEFER CONTAINER\", \"OPEN TOP\", \"FLAT RACK\"]),\n",
    "            \"quantity\": random.randint(1, 5)\n",
    "        },\n",
    "        \"routeDetails\": {\n",
    "            \"placeOfReceipt\": port_of_loading,\n",
    "            \"portOfLoading\": port_of_loading,\n",
    "            \"portOfDischarge\": port_of_discharge,\n",
    "            \"placeOfDelivery\": port_of_discharge\n",
    "        },\n",
    "        \"scheduleDetails\": {\n",
    "            \"estimatedArrivalAtLoadingPort\": (datetime.now() + timedelta(days=random.randint(1, 30))).strftime(\"%Y-%m-%d %H:%M\"),\n",
    "            \"estimatedDepartureFromLoadingPort\": (datetime.now() + timedelta(days=random.randint(31, 60))).strftime(\"%Y-%m-%d %H:%M\"),\n",
    "            \"estimatedArrivalAtDischargePort\": (datetime.now() + timedelta(days=random.randint(61, 90))).strftime(\"%Y-%m-%d %H:%M\")\n",
    "        },\n",
    "        \"emptyContainerPickupLocation\": f\"{random.choice(WESTBOUND_PORTS['loading'])}, {random.choice(['CHINA', 'KOREA', 'JAPAN', 'VIETNAM'])}\",\n",
    "        \"shippingTerm\": random.choice([\"FOB\", \"CIF\", \"EXW\", \"FCA\", \"CPT\", \"CIP\", \"DAP\", \"DDP\"]),\n",
    "        \"remarks\": \"No special instructions\"\n",
    "    }\n",
    "\n",
    "    # Ensure all fields from the sample structure are present\n",
    "    for key, value in sample_structure.items():\n",
    "        if key not in data:\n",
    "            data[key] = value\n",
    "\n",
    "    return data\n",
    "\n",
    "def generate_out_of_gauge_info(remarks):\n",
    "    lengths = [\"8m\", \"9m\", \"10m\", \"11m\", \"12m\"]\n",
    "    widths = [\"2.5m\", \"3m\", \"3.5m\", \"4m\"]\n",
    "    heights = [\"3m\", \"3.5m\", \"4m\", \"4.5m\", \"5m\"]\n",
    "    \n",
    "    return {\n",
    "        \"length\": random.choice(lengths),\n",
    "        \"width\": random.choice(widths),\n",
    "        \"height\": random.choice(heights),\n",
    "        \"weight\": f\"{random.randint(20000, 40000)}kg\"\n",
    "    }\n",
    "\n",
    "def generate_dangerous_goods_info(remarks):\n",
    "    un_numbers = [\"1202\", \"1203\", \"1223\", \"1267\", \"1993\"]\n",
    "    classes = [\"3\", \"4.1\", \"4.2\", \"5.1\", \"6.1\", \"8\", \"9\"]\n",
    "    proper_shipping_names = [\n",
    "        \"Flammable liquid, n.o.s.\",\n",
    "        \"Corrosive liquid, n.o.s.\",\n",
    "        \"Toxic liquid, organic, n.o.s.\",\n",
    "        \"Oxidizing liquid, n.o.s.\",\n",
    "        \"Environmentally hazardous substance, liquid, n.o.s.\"\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"unNumber\": random.choice(un_numbers),\n",
    "        \"class\": random.choice(classes),\n",
    "        \"properShippingName\": random.choice(proper_shipping_names),\n",
    "        \"packingGroup\": random.choice([\"I\", \"II\", \"III\"]),\n",
    "        \"flashpoint\": f\"{random.randint(-20, 100)}°C\"\n",
    "    }\n",
    "\n",
    "def generate_reefer_settings(remarks):\n",
    "    temperatures = [\"-20°C\", \"-18°C\", \"-15°C\", \"-10°C\", \"-5°C\", \"0°C\", \"2°C\", \"4°C\", \"10°C\", \"15°C\"]\n",
    "    ventilations = [\"Off\", \"10%\", \"20%\", \"30%\", \"40%\", \"50%\", \"60%\", \"70%\", \"80%\", \"90%\", \"100%\"]\n",
    "    humidity_levels = [\"60%\", \"65%\", \"70%\", \"75%\", \"80%\", \"85%\", \"90%\"]\n",
    "    \n",
    "    return {\n",
    "        \"temperature\": random.choice(temperatures),\n",
    "        \"ventilation\": random.choice(ventilations),\n",
    "        \"humidityLevel\": random.choice(humidity_levels),\n",
    "        \"o2Level\": f\"{random.randint(2, 21)}%\",\n",
    "        \"co2Level\": f\"{random.randint(0, 30)}%\"\n",
    "    }\n",
    "\n",
    "def generate_si_sample(model, tokenizer, sample_data, bkg_data, max_tokens=2048):\n",
    "    instruction = f\"\"\"\n",
    "    Generate a new JSON object for a Shipping Instruction based on the following structure and examples:\n",
    "    {json.dumps(random.choice(sample_data), indent=2)}\n",
    "\n",
    "    Ensure all fields are filled with realistic and varied data. \n",
    "    Modify values, names, and details to create a unique SI while maintaining the overall structure.\n",
    "    Use the following booking data as reference and ensure consistency:\n",
    "    {json.dumps(bkg_data, indent=2)}\n",
    "    The output should be a valid JSON object.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f'<s>[INST] {instruction} [/INST]\\n'\n",
    "    \n",
    "    generated_text = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt=prompt, \n",
    "        max_tokens=max_tokens,\n",
    "        temp=0.7,\n",
    "        top_p=0.95,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    generated_text = generated_text.replace(prompt, \"\").strip()\n",
    "    \n",
    "    start = generated_text.find('{')\n",
    "    end = generated_text.rfind('}')\n",
    "    \n",
    "def generate_si_sample(model, tokenizer, sample_data, bkg_data, max_tokens=2048):\n",
    "    instruction = f\"\"\"\n",
    "    Generate a new JSON object for a Shipping Instruction based on the following structure and examples:\n",
    "    {json.dumps(random.choice(sample_data), indent=2)}\n",
    "\n",
    "    Ensure all fields are filled with realistic and varied data. \n",
    "    Modify values, names, and details to create a unique SI while maintaining the overall structure.\n",
    "    Use the following booking data as reference and ensure consistency:\n",
    "    {json.dumps(bkg_data, indent=2)}\n",
    "    The output should be a valid JSON object.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f'<s>[INST] {instruction} [/INST]\\n'\n",
    "    \n",
    "    generated_text = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt=prompt, \n",
    "        max_tokens=max_tokens,\n",
    "        temp=0.7,\n",
    "        top_p=0.95,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    generated_text = generated_text.replace(prompt, \"\").strip()\n",
    "    \n",
    "    start = generated_text.find('{')\n",
    "    end = generated_text.rfind('}')\n",
    "    \n",
    "    if start != -1 and end != -1 and start < end:\n",
    "        json_str = generated_text[start:end+1]\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "            sample_structure = random.choice(sample_data)\n",
    "            \n",
    "            # Ensure the generated data follows the sample structure\n",
    "            for key in sample_structure.keys():\n",
    "                if key not in data:\n",
    "                    data[key] = sample_structure[key]\n",
    "            \n",
    "            # Ensure key information is consistent with BKG data\n",
    "            data[\"bookingReference\"] = bkg_data[\"bookingReference\"]\n",
    "            data[\"voyageDetails\"] = bkg_data[\"voyageDetails\"]\n",
    "            data[\"routeDetails\"] = bkg_data[\"routeDetails\"]\n",
    "            \n",
    "            # Ensure shipper name is the same\n",
    "            if \"shipperName\" in bkg_data:\n",
    "                if \"partyDetails\" not in data:\n",
    "                    data[\"partyDetails\"] = {}\n",
    "                if \"shipper\" not in data[\"partyDetails\"]:\n",
    "                    data[\"partyDetails\"][\"shipper\"] = {}\n",
    "                data[\"partyDetails\"][\"shipper\"][\"name\"] = bkg_data[\"shipperName\"]\n",
    "            \n",
    "            # Process remarks and generate special information\n",
    "            if \"remarks\" in bkg_data:\n",
    "                if \"additionalInformation\" not in data:\n",
    "                    data[\"additionalInformation\"] = {}\n",
    "                data[\"additionalInformation\"][\"additionalRemarks\"] = bkg_data[\"remarks\"]\n",
    "                \n",
    "                remarks = bkg_data[\"remarks\"].lower()\n",
    "                \n",
    "                # Check for Out of Gauge\n",
    "                if \"out of gauge\" in remarks or \"oog\" in remarks:\n",
    "                    data[\"outOfGaugeDimensions\"] = generate_out_of_gauge_info(remarks)\n",
    "                \n",
    "                # Check for Dangerous Goods\n",
    "                if \"dangerous goods\" in remarks or \"hazardous\" in remarks:\n",
    "                    data[\"dangerousGoods\"] = generate_dangerous_goods_info(remarks)\n",
    "                \n",
    "                # Check for Reefer\n",
    "                if \"reefer\" in remarks or \"temperature controlled\" in remarks:\n",
    "                    data[\"reeferSettings\"] = generate_reefer_settings(remarks)\n",
    "            \n",
    "            # Ensure onboardDate is the same as estimatedArrivalAtLoadingPort\n",
    "            if \"scheduleDetails\" in bkg_data and \"estimatedArrivalAtLoadingPort\" in bkg_data[\"scheduleDetails\"]:\n",
    "                if \"additionalInformation\" not in data:\n",
    "                    data[\"additionalInformation\"] = {}\n",
    "                data[\"additionalInformation\"][\"onboardDate\"] = bkg_data[\"scheduleDetails\"][\"estimatedArrivalAtLoadingPort\"]\n",
    "            \n",
    "            # Remove containerDetails from SI data if it exists\n",
    "            if \"containerDetails\" in data:\n",
    "                del data[\"containerDetails\"]\n",
    "            \n",
    "            # Ensure all required fields from the sample structure are present\n",
    "            for key, value in sample_structure.items():\n",
    "                if key not in data:\n",
    "                    data[key] = value\n",
    "            \n",
    "            return data\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to parse JSON. Retrying...\")\n",
    "    else:\n",
    "        print(\"No valid JSON structure found. Retrying...\")\n",
    "    return None\n",
    "\n",
    "def create_samples(model, tokenizer, sample_data_bkg, sample_data_si, output_dir_bkg, output_dir_si, num_samples=10000):\n",
    "    sample_data_bkg = load_sample_data(sample_data_bkg)\n",
    "    sample_data_si = load_sample_data(sample_data_si)\n",
    "    \n",
    "    os.makedirs(output_dir_bkg, exist_ok=True)\n",
    "    os.makedirs(output_dir_si, exist_ok=True)\n",
    "    \n",
    "    print(f\"Generating {num_samples} pairs of Booking and SI samples...\")\n",
    "    for i in tqdm(range(num_samples), desc=\"Generating samples\"):\n",
    "        booking_reference = generate_booking_reference()\n",
    "        \n",
    "        retry_count = 0\n",
    "        while retry_count < 5:  # Limit the number of retries\n",
    "            bkg_data = generate_bkg_sample(model, tokenizer, sample_data_bkg, booking_reference)\n",
    "            if bkg_data:\n",
    "                si_data = generate_si_sample(model, tokenizer, sample_data_si, bkg_data)\n",
    "                if si_data:\n",
    "                    bkg_filename = f\"bkg_{booking_reference}.json\"\n",
    "                    si_filename = f\"si_{booking_reference}.json\"\n",
    "                    \n",
    "                    with open(os.path.join(output_dir_bkg, bkg_filename), 'w') as f:\n",
    "                        json.dump(bkg_data, f, indent=2)\n",
    "                    with open(os.path.join(output_dir_si, si_filename), 'w') as f:\n",
    "                        json.dump(si_data, f, indent=2)\n",
    "                    break\n",
    "            retry_count += 1\n",
    "        if retry_count == 5:\n",
    "            print(f\"Failed to generate valid JSON for sample {i+1} after 5 attempts. Skipping...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = load_model_and_tokenizer()\n",
    "    sample_data_bkg = \"./bkg/\"\n",
    "    sample_data_si = \"./si/\"\n",
    "    output_dir_bkg = \"./bkg_data/\"\n",
    "    output_dir_si = \"./si_data/\"\n",
    "    create_samples(model, tokenizer, sample_data_bkg, sample_data_si, output_dir_bkg, output_dir_si, num_samples=10000)\n",
    "    print(\"Sample generation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable remarks in bkg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10735c8944884636a4c55917a5cfc3af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10000 pairs of Booking and SI samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples:   0%|          | 25/10000 [1:04:18<423:03:40, 152.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse JSON. Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples:   1%|          | 57/10000 [2:32:08<428:11:43, 155.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse JSON. Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples:   1%|          | 62/10000 [2:48:35<447:26:31, 162.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse JSON. Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples:   1%|          | 65/10000 [3:00:11<459:01:04, 166.33s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 357\u001b[0m\n\u001b[1;32m    355\u001b[0m output_dir_bkg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./bkg_data/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    356\u001b[0m output_dir_si \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./si_data/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 357\u001b[0m \u001b[43mcreate_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_data_bkg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_data_si\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir_bkg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir_si\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample generation completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 335\u001b[0m, in \u001b[0;36mcreate_samples\u001b[0;34m(model, tokenizer, sample_data_bkg, sample_data_si, output_dir_bkg, output_dir_si, num_samples)\u001b[0m\n\u001b[1;32m    333\u001b[0m retry_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retry_count \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m5\u001b[39m:  \u001b[38;5;66;03m# Limit the number of retries\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m     bkg_data \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_bkg_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_data_bkg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbooking_reference\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bkg_data:\n\u001b[1;32m    337\u001b[0m         si_data \u001b[38;5;241m=\u001b[39m generate_si_sample(model, tokenizer, sample_data_si, bkg_data)\n",
      "Cell \u001b[0;32mIn[1], line 127\u001b[0m, in \u001b[0;36mgenerate_bkg_sample\u001b[0;34m(model, tokenizer, sample_data, booking_reference, max_tokens)\u001b[0m\n\u001b[1;32m    109\u001b[0m instruction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124mGenerate a new JSON object for a Booking based on the following structure:\u001b[39m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson\u001b[38;5;241m.\u001b[39mdumps(sample_structure,\u001b[38;5;250m \u001b[39mindent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124mThe output should be a valid JSON object.\u001b[39m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    125\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<s>[INST] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstruction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [/INST]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 127\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m generated_text\u001b[38;5;241m.\u001b[39mreplace(prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    139\u001b[0m start \u001b[38;5;241m=\u001b[39m generated_text\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlx/lib/python3.11/site-packages/mlx_lm/utils.py:331\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(model, tokenizer, prompt, max_tokens, verbose, formatter, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    329\u001b[0m detokenizer\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 331\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerate_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperf_counter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtic\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlx/lib/python3.11/site-packages/mlx_lm/utils.py:248\u001b[0m, in \u001b[0;36mgenerate_step\u001b[0;34m(prompt, model, temp, repetition_penalty, repetition_context_size, top_p, min_p, min_tokens_to_keep, logit_bias, prefill_step_size, max_kv_size)\u001b[0m\n\u001b[1;32m    246\u001b[0m next_y, next_logprobs \u001b[38;5;241m=\u001b[39m _step(y)\n\u001b[1;32m    247\u001b[0m mx\u001b[38;5;241m.\u001b[39masync_eval(next_y)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, logprobs\n\u001b[1;32m    249\u001b[0m y, logprobs \u001b[38;5;241m=\u001b[39m next_y, next_logprobs\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "# Constants for the specific conditions\n",
    "WESTBOUND_PORTS = {\n",
    "    \"loading\": [\"NINGBO\", \"SHANGHAI\", \"YANTIAN\", \"SINGAPORE\", \"TANGER\", \"LE HAVRE\"],\n",
    "    \"discharge\": [\"LE HAVRE\", \"HAMBURG\", \"GDANSK\", \"ROTTERDAM\", \"ALGECIRAS\", \"PORT KLANG\", \"NINGBO\"]\n",
    "}\n",
    "\n",
    "EASTBOUND_PORTS = {\n",
    "    \"loading\": [\"LE HAVRE\", \"HAMBURG\", \"GDANSK\", \"ROTTERDAM\", \"ALGECIRAS\", \"PORT KLANG\", \"NINGBO\"],\n",
    "    \"discharge\": [\"NINGBO\", \"SHANGHAI\", \"YANTIAN\", \"SINGAPORE\", \"TANGER\", \"LE HAVRE\"]\n",
    "}\n",
    "\n",
    "VESSELS = [\n",
    "    \"APL CHANGI\", \"APL MERLION\", \"APL RAFFLES\", \"APL SINGAPURA\", \"APL TEMASEK\",\n",
    "    \"APL VANDA\", \"CMA CGM ALEXANDER VON HUMBOLDT\", \"CMA CGM BENJAMIN FRANKLIN\",\n",
    "    \"CMA CGM BOUGAINVILLE\", \"CMA CGM EOURES\", \"CMA CGM GEORG FORSTER\",\n",
    "    \"CMA CGM GRACE BAY\", \"CMA CGM ROQUEVAIRE\", \"CMA CGM VASCO DE GAMA\",\n",
    "    \"CMA CGM ZHENG HE\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    print(\"Loading model and tokenizer...\")\n",
    "    model, tokenizer = load(\"mlx-community/gemma-2-27b-it-4bit\")\n",
    "    return model, tokenizer\n",
    "\n",
    "def load_sample_data(directory):\n",
    "    sample_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(directory, filename), 'r') as f:\n",
    "                sample_data.append(json.load(f))\n",
    "    return sample_data\n",
    "\n",
    "def generate_booking_reference():\n",
    "    today = datetime.now()\n",
    "    random_days = random.randint(0, 60)  # 0에서 60일 사이의 랜덤한 일수\n",
    "    future_date = today + timedelta(days=random_days)\n",
    "    return f\"CHERRY{future_date.strftime('%Y%m%d')}{random.randint(1000, 9999)}\"\n",
    "\n",
    "def generate_remarks():\n",
    "    remarks = []\n",
    "    \n",
    "    # 컨테이너 타입 선택\n",
    "    container_types = [\"DRY\", \"HC\", \"FLAT RACK\", \"OPEN TOP\", \"REEFER\"]\n",
    "    cargo_type = random.choice([\"GENERAL\", \"OUT_OF_GAUGE\", \"REEFER\", \"DANGEROUS\"])\n",
    "    \n",
    "    if cargo_type == \"OUT_OF_GAUGE\":\n",
    "        container_type = random.choice([\"FLAT RACK\", \"OPEN TOP\"])\n",
    "        length = random.randint(2000, 12000)\n",
    "        width = random.randint(2000, 3000)\n",
    "        height = random.randint(2000, 3000)\n",
    "        remarks.append(f\"Container Type: {container_type}\")\n",
    "        remarks.append(f\"Out of Gauge Cargo, LxWxH(mm): {length}x{width}x{height}\")\n",
    "    \n",
    "    elif cargo_type == \"REEFER\":\n",
    "        container_type = \"REEFER\"\n",
    "        temp = random.randint(-20, 20)\n",
    "        remarks.append(f\"Container Type: {container_type}\")\n",
    "        remarks.append(f\"Temperature Controlled Cargo: {temp}°C\")\n",
    "    \n",
    "    elif cargo_type == \"DANGEROUS\":\n",
    "        container_type = random.choice([\"DRY\", \"HC\"])  # 주로 DRY나 HC 사용\n",
    "        un_number = random.randint(1000, 3500)\n",
    "        remarks.append(f\"Container Type: {container_type}\")\n",
    "        remarks.append(f\"Dangerous Goods, UN {un_number}\")\n",
    "    \n",
    "    else:  # GENERAL cargo\n",
    "        container_type = random.choice([\"DRY\", \"HC\"])\n",
    "        remarks.append(f\"Container Type: {container_type}\")\n",
    "    \n",
    "    # 화물 가치\n",
    "    if random.random() < 0.5:  # 50% 확률로 화물 가치 정보 추가\n",
    "        value = random.randint(10000, 1000000)\n",
    "        remarks.append(f\"Value: USD{value:,}\")\n",
    "    \n",
    "    # Free Time\n",
    "    if random.random() < 0.4:  # 40% 확률로 Free Time 정보 추가\n",
    "        days = random.choice([7, 14, 21, 30])\n",
    "        remarks.append(f\"{days} Days Free Time at Destination\")\n",
    "    \n",
    "    # 특별 취급 지침\n",
    "    special_instructions = [\n",
    "        \"Handle with care\",\n",
    "        \"Keep dry\",\n",
    "        \"This side up\",\n",
    "        \"Fragile\",\n",
    "        \"Do not stack\"\n",
    "    ]\n",
    "    if random.random() < 0.3:  # 30% 확률로 특별 취급 지침 추가\n",
    "        remarks.append(random.choice(special_instructions))\n",
    "    \n",
    "    # remarks가 비어있으면 기본 메시지 추가\n",
    "    if not remarks:\n",
    "        remarks.append(\"No special instructions\")\n",
    "    \n",
    "    return \", \".join(remarks)\n",
    "\n",
    "def generate_bkg_sample(model, tokenizer, sample_data, booking_reference, max_tokens=2048):\n",
    "    sample_structure = random.choice(sample_data)\n",
    "\n",
    "    instruction = f\"\"\"\n",
    "    Generate a new JSON object for a Booking based on the following structure:\n",
    "    {json.dumps(sample_structure, indent=2)}\n",
    "\n",
    "    Use the following booking reference: {booking_reference}\n",
    "    \n",
    "    Consider the following ports for the route:\n",
    "    Westbound: {', '.join(WESTBOUND_PORTS['loading'] + WESTBOUND_PORTS['discharge'])}\n",
    "    Eastbound: {', '.join(EASTBOUND_PORTS['loading'] + EASTBOUND_PORTS['discharge'])}\n",
    "    \n",
    "    Available vessels: {', '.join(VESSELS)}\n",
    "\n",
    "    Ensure all fields are filled with realistic and varied data. \n",
    "    The output should be a valid JSON object.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f'<s>[INST] {instruction} [/INST]\\n'\n",
    "    \n",
    "    generated_text = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt=prompt, \n",
    "        max_tokens=max_tokens,\n",
    "        temp=0.7,\n",
    "        top_p=0.95,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    generated_text = generated_text.replace(prompt, \"\").strip()\n",
    "    \n",
    "    start = generated_text.find('{')\n",
    "    end = generated_text.rfind('}')\n",
    "    \n",
    "    if start != -1 and end != -1 and start < end:\n",
    "        json_str = generated_text[start:end+1]\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            # Ensure all required fields from the sample structure are present\n",
    "            for key, value in sample_structure.items():\n",
    "                if key not in data:\n",
    "                    data[key] = value\n",
    "            \n",
    "            # Ensure booking reference is correct\n",
    "            data[\"bookingReference\"] = booking_reference\n",
    "            \n",
    "            # Generate remarks if not present\n",
    "            if \"remarks\" not in data or not data[\"remarks\"]:\n",
    "                data[\"remarks\"] = generate_remarks()\n",
    "            \n",
    "            return data\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to parse JSON. Retrying...\")\n",
    "    else:\n",
    "        print(\"No valid JSON structure found. Retrying...\")\n",
    "    return None\n",
    "\n",
    "def generate_special_cargo_info(model, tokenizer, remarks, cargo_type, max_tokens=512):\n",
    "    instruction = f\"\"\"\n",
    "    Based on the following remarks for a shipping booking:\n",
    "    \"{remarks}\"\n",
    "\n",
    "    Generate realistic and detailed {cargo_type} information in JSON format.\n",
    "    Include all relevant fields and ensure the information is consistent with the remarks.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f'<s>[INST] {instruction} [/INST]\\n'\n",
    "    \n",
    "    generated_text = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt=prompt, \n",
    "        max_tokens=max_tokens,\n",
    "        temp=0.7,\n",
    "        top_p=0.95,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    generated_text = generated_text.replace(prompt, \"\").strip()\n",
    "    \n",
    "    start = generated_text.find('{')\n",
    "    end = generated_text.rfind('}')\n",
    "    \n",
    "    if start != -1 and end != -1 and start < end:\n",
    "        json_str = generated_text[start:end+1]\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "            return data\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to parse {cargo_type} JSON. Using default generation.\")\n",
    "    else:\n",
    "        print(f\"No valid {cargo_type} JSON structure found. Using default generation.\")\n",
    "    \n",
    "    # Fallback to default generation if LLM fails\n",
    "    if cargo_type == \"Out of Gauge\":\n",
    "        return generate_out_of_gauge_info(remarks)\n",
    "    elif cargo_type == \"Dangerous Goods\":\n",
    "        return generate_dangerous_goods_info(remarks)\n",
    "    elif cargo_type == \"Reefer Settings\":\n",
    "        return generate_reefer_settings(remarks)\n",
    "\n",
    "def generate_si_sample(model, tokenizer, sample_data, bkg_data, max_tokens=2048):\n",
    "    instruction = f\"\"\"\n",
    "    Generate a new JSON object for a Shipping Instruction based on the following structure and examples:\n",
    "    {json.dumps(random.choice(sample_data), indent=2)}\n",
    "\n",
    "    Ensure all fields are filled with realistic and varied data. \n",
    "    Modify values, names, and details to create a unique SI while maintaining the overall structure.\n",
    "    Use the following booking data as reference and ensure consistency:\n",
    "    {json.dumps(bkg_data, indent=2)}\n",
    "    The output should be a valid JSON object.\n",
    "    Do not include any special cargo information (such as outOfGaugeDimensions, dangerousGoods, or reeferSettings) unless explicitly mentioned in the booking remarks.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f'<s>[INST] {instruction} [/INST]\\n'\n",
    "    \n",
    "    generated_text = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt=prompt, \n",
    "        max_tokens=max_tokens,\n",
    "        temp=0.7,\n",
    "        top_p=0.95,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    generated_text = generated_text.replace(prompt, \"\").strip()\n",
    "    \n",
    "    start = generated_text.find('{')\n",
    "    end = generated_text.rfind('}')\n",
    "    \n",
    "    if start != -1 and end != -1 and start < end:\n",
    "        json_str = generated_text[start:end+1]\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "            sample_structure = random.choice(sample_data)\n",
    "            \n",
    "            # Ensure the generated data follows the sample structure\n",
    "            for key in sample_structure.keys():\n",
    "                if key not in data:\n",
    "                    data[key] = sample_structure[key]\n",
    "            \n",
    "            # Ensure key information is consistent with BKG data\n",
    "            data[\"bookingReference\"] = bkg_data[\"bookingReference\"]\n",
    "            data[\"voyageDetails\"] = bkg_data[\"voyageDetails\"]\n",
    "            data[\"routeDetails\"] = bkg_data[\"routeDetails\"]\n",
    "            \n",
    "            # Ensure shipper name is the same\n",
    "            if \"shipperName\" in bkg_data:\n",
    "                if \"partyDetails\" not in data:\n",
    "                    data[\"partyDetails\"] = {}\n",
    "                if \"shipper\" not in data[\"partyDetails\"]:\n",
    "                    data[\"partyDetails\"][\"shipper\"] = {}\n",
    "                data[\"partyDetails\"][\"shipper\"][\"name\"] = bkg_data[\"shipperName\"]\n",
    "            \n",
    "            # Process remarks and generate special information\n",
    "            if \"remarks\" in bkg_data:\n",
    "                remarks = bkg_data[\"remarks\"].lower()\n",
    "                \n",
    "                # Always remove any existing special cargo information\n",
    "                data.pop(\"outOfGaugeDimensions\", None)\n",
    "                data.pop(\"dangerousGoods\", None)\n",
    "                data.pop(\"reeferSettings\", None)\n",
    "                \n",
    "                # Check for Out of Gauge (only if explicitly mentioned)\n",
    "                if \"out of gauge\" in remarks or \"oog\" in remarks:\n",
    "                    data[\"outOfGaugeDimensions\"] = generate_special_cargo_info(model, tokenizer, bkg_data[\"remarks\"], \"Out of Gauge\")\n",
    "                \n",
    "                # Check for Dangerous Goods (only if explicitly mentioned)\n",
    "                if \"dangerous goods\" in remarks or \"hazardous\" in remarks:\n",
    "                    data[\"dangerousGoods\"] = generate_special_cargo_info(model, tokenizer, bkg_data[\"remarks\"], \"Dangerous Goods\")\n",
    "                \n",
    "                # Check for Reefer (only if explicitly mentioned)\n",
    "                if \"reefer\" in remarks or \"temperature controlled\" in remarks:\n",
    "                    data[\"reeferSettings\"] = generate_special_cargo_info(model, tokenizer, bkg_data[\"remarks\"], \"Reefer Settings\")\n",
    "                \n",
    "                # Add remarks to additionalInformation\n",
    "                if \"additionalInformation\" not in data:\n",
    "                    data[\"additionalInformation\"] = {}\n",
    "                data[\"additionalInformation\"][\"additionalRemarks\"] = bkg_data[\"remarks\"]\n",
    "            \n",
    "            # Ensure onboardDate is the same as estimatedArrivalAtLoadingPort\n",
    "            if \"scheduleDetails\" in bkg_data and \"estimatedArrivalAtLoadingPort\" in bkg_data[\"scheduleDetails\"]:\n",
    "                if \"additionalInformation\" not in data:\n",
    "                    data[\"additionalInformation\"] = {}\n",
    "                data[\"additionalInformation\"][\"onboardDate\"] = bkg_data[\"scheduleDetails\"][\"estimatedArrivalAtLoadingPort\"]\n",
    "            \n",
    "            # Remove containerDetails from SI data if it exists\n",
    "            if \"containerDetails\" in data:\n",
    "                del data[\"containerDetails\"]\n",
    "            \n",
    "            # Ensure all required fields from the sample structure are present\n",
    "            for key, value in sample_structure.items():\n",
    "                if key not in data:\n",
    "                    data[key] = value\n",
    "            \n",
    "            # Final check to remove any special cargo information not explicitly mentioned in remarks\n",
    "            if \"remarks\" in bkg_data:\n",
    "                remarks = bkg_data[\"remarks\"].lower()\n",
    "                if \"out of gauge\" not in remarks and \"oog\" not in remarks:\n",
    "                    data.pop(\"outOfGaugeDimensions\", None)\n",
    "                if \"dangerous goods\" not in remarks and \"hazardous\" not in remarks:\n",
    "                    data.pop(\"dangerousGoods\", None)\n",
    "                if \"reefer\" not in remarks and \"temperature controlled\" not in remarks:\n",
    "                    data.pop(\"reeferSettings\", None)\n",
    "            \n",
    "            return data\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to parse JSON. Retrying...\")\n",
    "    else:\n",
    "        print(\"No valid JSON structure found. Retrying...\")\n",
    "    return None\n",
    "\n",
    "def create_samples(model, tokenizer, sample_data_bkg, sample_data_si, output_dir_bkg, output_dir_si, num_samples=10000):\n",
    "    sample_data_bkg = load_sample_data(sample_data_bkg)\n",
    "    sample_data_si = load_sample_data(sample_data_si)\n",
    "    \n",
    "    os.makedirs(output_dir_bkg, exist_ok=True)\n",
    "    os.makedirs(output_dir_si, exist_ok=True)\n",
    "    \n",
    "    print(f\"Generating {num_samples} pairs of Booking and SI samples...\")\n",
    "    for i in tqdm(range(num_samples), desc=\"Generating samples\"):\n",
    "        booking_reference = generate_booking_reference()\n",
    "        \n",
    "        retry_count = 0\n",
    "        while retry_count < 5:  # Limit the number of retries\n",
    "            bkg_data = generate_bkg_sample(model, tokenizer, sample_data_bkg, booking_reference)\n",
    "            if bkg_data:\n",
    "                si_data = generate_si_sample(model, tokenizer, sample_data_si, bkg_data)\n",
    "                if si_data:\n",
    "                    bkg_filename = f\"bkg_{booking_reference}.json\"\n",
    "                    si_filename = f\"si_{booking_reference}.json\"\n",
    "                    \n",
    "                    with open(os.path.join(output_dir_bkg, bkg_filename), 'w') as f:\n",
    "                        json.dump(bkg_data, f, indent=2)\n",
    "                    with open(os.path.join(output_dir_si, si_filename), 'w') as f:\n",
    "                        json.dump(si_data, f, indent=2)\n",
    "                    break\n",
    "            retry_count += 1\n",
    "        if retry_count == 5:\n",
    "            print(f\"Failed to generate valid JSON for sample {i+1} after 5 attempts. Skipping...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = load_model_and_tokenizer()\n",
    "    sample_data_bkg = \"./bkg/\"\n",
    "    sample_data_si = \"./si/\"\n",
    "    output_dir_bkg = \"./bkg_data/\"\n",
    "    output_dir_si = \"./si_data/\"\n",
    "    create_samples(model, tokenizer, sample_data_bkg, sample_data_si, output_dir_bkg, output_dir_si, num_samples=10000)\n",
    "    print(\"Sample generation completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
